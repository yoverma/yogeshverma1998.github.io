#  **An evolving trajectory in drug design**

<!--[![download](https://img.shields.io/badge/download-review-blue.svg)](https://iml-wg.github.io/HEPML-LivingReview/review/hepml-review.pdf)-->

The purpose of this note is to act as a one place repository for all the literature read, presentations and ideas which have been formulated reside here and act as a one go place. The literature read has been segregated in different domains ranging from dynamics to representing molecule as a 3d object. Paper which are being currently read and analyzed are marked with üìù.

```diff
- Paper Count = 77 /1280
+ Reading = 5
```

*  Dynamics

      * [ODE<sup>2</sup>VAE](https://arxiv.org/pdf/1905.10994.pdf)
      * [Neural ODEs](https://arxiv.org/pdf/1806.07366.pdf)
      * [Neural Flows](https://proceedings.neurips.cc/paper/2021/file/b21f9f98829dea9a48fd8aaddc1f159d-Paper.pdf)
      * [FFJORD](https://arxiv.org/pdf/1810.01367.pdf)
      * [Neural Processes](https://arxiv.org/abs/1807.01622)
      * [Review of Normalizing flows](https://arxiv.org/pdf/1912.02762.pdf) üìù
      * [Variational multiple shooting for Bayesian ODEs with Gaussian processes](https://arxiv.org/pdf/2106.10905.pdf)
      * [Non-Autoregressive neural machine translation](https://openreview.net/pdf?id=B1l8BtlCb) üìù
      * [Your classifier is secretly an energy based model and you should treat it like one](https://arxiv.org/abs/1912.03263)
      * [Neural Relational Inference for Interacting systems](https://arxiv.org/pdf/2102.10240.pdf)
      * [Graph Normalizing flows](https://arxiv.org/pdf/1905.13177.pdf)
      * [Learning Continuous-time PDEs from sparse data with GNNs](https://arxiv.org/abs/2006.08956)
      * [PointFlow](https://arxiv.org/pdf/1906.12320.pdf)
      * [Evolving-Graph Gaussian Processes](https://arxiv.org/abs/2106.15127#:~:text=Graph%20Gaussian%20Processes%20(GGPs)%20provide,limiting%20the%20applications%20of%20GGPs.)
      * [Conditional Random fields](https://arxiv.org/abs/2106.15127#:~:text=Graph%20Gaussian%20Processes%20(GGPs)%20provide,limiting%20the%20applications%20of%20GGPs.)
      * [PDE-GCN: Novel Architectures for Graph Neural Networks Motivated by Partial Differential Equations](https://arxiv.org/abs/2108.01938)
      * [Spherical Message passing for 3D Graph Networks](https://openreview.net/forum?id=givsRXsOt9r)
      * [Simple GNN Regularisation for 3D Molecule Property prediction](https://openreview.net/forum?id=1wVvweK3oIb)
      * [Message Passing Neural PDE Solvers](https://arxiv.org/abs/2202.03376)
      * [Temporal Graph Networks](https://arxiv.org/abs/2006.10637)
      * [Neural Controlled Differential Equations](https://arxiv.org/abs/2005.08926)
      * [Variational Neural Cellular Automata](https://openreview.net/pdf?id=7fFO4cMBx_9)
      * [Learning to generate 3D shapes with generative cellular automata](https://arxiv.org/abs/2103.04130)
      * [Neural process with stochastic attention](http://arxiv.org/abs/2204.05449#:~:text=Neural%20Processes%20with%20Stochastic%20Attention%3A%20Paying%20more%20attention%20to%20the%20context%20dataset,-Mingyu%20Kim%2C%20Kyeongryeol&text=Neural%20processes%20(NPs)%20aim%20to,identifier%20for%20a%20novel%20task.)
      * [Handling distribution shifts in graphs](https://arxiv.org/abs/2202.02466)
      * [Learning to Solve PDE-constrained Inverse Problems with Graph Networks](https://arxiv.org/abs/2206.00711)
      * [Topological graph neural networks](https://arxiv.org/abs/2102.07835)
      * [Graph Coupled Oscillator Networks](https://arxiv.org/abs/2202.02296)
      * [Graph Condensation for Graph Neural Networks](https://arxiv.org/abs/2110.07580)
      * [Sign and Basis Invariant Networks for Spectral Graph Representation Learning](https://arxiv.org/abs/2202.13013)
      
* Physics Inspired ML

     * [Noether Networks](https://arxiv.org/pdf/2112.03321.pdf)
     * [Interaction Networks for Learning about Objects,Relations and Physics](https://arxiv.org/pdf/1612.00222.pdf)
     * [Physics Informed Machine Learning](https://www.nature.com/articles/s42254-021-00314-5.pdf)
     * [Deconstructing the inductive biases of Hamiltonian neural networks](https://arxiv.org/pdf/2202.04836.pdf)
     * [Hamiltonian graph networks with ODE integrators](https://arxiv.org/abs/1909.12790)
     * [Predicting physics in mesh-reduced space with temporal attention](https://arxiv.org/abs/2201.09113)
    

*  Conformer generation and structure prediction

      * [Learning Gradient Fields for Molecular Conformation Generation](https://arxiv.org/pdf/2105.03902.pdf)
      * [DGSM](https://proceedings.neurips.cc/paper/2021/file/a45a1d12ee0fb7f1f872ab91da18f899-Paper.pdf)
      * [Learning neural generative dynamics for molecular conformation generation](https://arxiv.org/pdf/2102.10240.pdf)
      * [Geometric Deep Learning on Molecular Representations](https://arxiv.org/pdf/2107.12375.pdf)
      * [EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction](https://arxiv.org/pdf/2202.05146.pdf)
      * [Spanning Tree-based Graph Generation for Molecules](https://openreview.net/forum?id=w60btE_8T2m)
      * [Molecular Surface Representation Using 3D Zernike Descriptors for Protein Shape
Comparison and Docking](https://pubmed.ncbi.nlm.nih.gov/21787306/)
      * [Categorical Normalizing Flow](https://arxiv.org/pdf/2006.09790.pdf)
      * [GraphDF: A Discrete Flow Model for Molecular Graph Generation](https://arxiv.org/abs/2102.01189)
      * [GraphNVP](https://arxiv.org/abs/1905.11600)
      * [Dual use of artifcial-intelligence-powered drug discovery](https://www.nature.com/articles/s42256-022-00465-9.pdf)
      * [Energy-Inspired Molecular Conformation Optimization](https://openreview.net/forum?id=7QfLW-XZTl)
      * [Chemical-Reaction-Aware Molecule Representation Learning](https://arxiv.org/abs/2109.09888)
      * [Evaluating generalization in Gflow Nets for molecule design](https://openreview.net/pdf?id=JFSaHKNZ35b)
      * [An auto regressive flow model for 3D molecular geometry generation from scratch](https://openreview.net/forum?id=C03Ajc-NS5W)
      * [Molecular RNN](https://arxiv.org/abs/1705.04612)
      * [Learning to extend molecular scaffolds with structural motifs](https://arxiv.org/abs/2103.03864)
      * [Learning 3D representations of molecular chirality with invariance to bond rotations](https://arxiv.org/abs/2110.04383)
      * [Pre-training molecular graph representation with 3D geometry](https://arxiv.org/abs/2110.07728)
      * [DATA-EFFICIENT GRAPH GRAMMAR LEARNING FOR MOLECULAR GENERATION](https://openreview.net/forum?id=l4IHywGq6a)
      * [Geometric Transformers for protein interface contact prediction](https://arxiv.org/abs/2110.02423)
      * [A 3D Molecule Generative Model for Structure-Based Drug Design](https://arxiv.org/abs/2203.10446)
      * [Crystal Diffusion Variational Autoencoder for Periodic Material Generation](https://arxiv.org/abs/2110.06197)
      * [Generating 3D Molecules for Target Protein Binding](https://arxiv.org/abs/2204.09410)
      * [Generative Coarse-Graining of Molecular Conformations](https://arxiv.org/abs/2201.12176#:~:text=Coarse%2Dgraining%20(CG)%20of,and%20therefore%20drastically%20accelerates%20simulation.)
      
      

*  Diffusion, SDE and Score Matching Methods

      * [GeoDiff](https://openreview.net/pdf?id=PzcvxEMzvQC)
      * [Diffusion Kernels on Graphs and Other Discrete Input Spaces](https://www.ml.cmu.edu/research/dap-papers/kondor-diffusion-kernels.pdf)
      * [Denoising Probabilistic Diffusion models](https://arxiv.org/abs/2006.11239)
      * [Estimation of Non-Normalized Statistical Models by Score Matching](https://jmlr.org/papers/volume6/hyvarinen05a/old.pdf)
      * [GRAND: Graph Neural Diffusion](https://arxiv.org/abs/2106.10934)
      * [Learning energy-based models by diffusion recovery likelihood](https://arxiv.org/abs/2012.08125)
      * [Denoising Diffusion GANs](http://arxiv.org/abs/2112.07804)
      * [Scalable Gradients for SDE](https://arxiv.org/abs/2001.01328)
      * [Graph Anisotropic Diffusion](https://arxiv.org/abs/2205.00354)
      * [Auto-Regressive Diffusion Models](https://arxiv.org/abs/2110.02037)
      * [GRAND++](https://openreview.net/forum?id=EMxu-dzvJk)
      * [Reimaninan Neural SDE](https://openreview.net/pdf?id=SF8lkH-J6e9)
      * [Neural Sheaf Diffusion](https://openreview.net/forum?id=HtLzqEb1aec)
      * [Neural SDEs as Infinite-Dimensional GANs](https://arxiv.org/pdf/2102.03657)
      * [Score-based generative modeling through SDE](https://arxiv.org/abs/2011.13456)

*  RL

      * [Reinforcement Learning and Control as Probabilistic Inference](https://arxiv.org/pdf/1805.00909.pdf) üìù
  
  
         
<!-- *  Slides Presented:
     
      * [26/01/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_260122.pdf) [Regular meeting]
      * [2/02/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_02022022.pdf) [Regular Meeting]
      * [10/2/2022](https://aaltofi-my.sharepoint.com/:p:/g/personal/yogesh_verma_aalto_fi/EWoJvVJtTjxMq-VD1zCVh_0B0aj8D7Ukapw7A-fc68ksSA?e=0k0jAU)[Regular Meeting]
      * [16/2/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_16022022.pdf)[Regular Meeting]
      * [23/2/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_23022022.pdf)[Regular Meeting]
      * [02/3/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_02032022.pdf)[Regular Meeting]
      * [09/3/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_09032022.pdf)[Regular Meeting]
      * [16/3/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_16032022.pdf)[Regular Meeting]
      * [23/3/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_23032022.pdf)[Regular Meeting]
      * [30/3/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_30032022.pdf)[Regular Meeting]
      * [06/4/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_06042022.pdf)[Regular Meeting]
      * [13/4/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_13042022.pdf)[Regular Meeting]
      * [20/4/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_20042022.pdf)[Regular Meeting]
      * [27/4/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_27042022.pdf)[Regular Meeting]
      * [04/05/2022]()[Regular Meeting]
      * [25/05/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_25052022.pdf)[Regular Meeting]
      * [01/06/2022](https://github.com/yogeshverma1998/yogeshverma1998.github.io/blob/main/ppt_01062022.pdf)[Regular Meeting] -->















<!--

#  **A Living Review of Machine Learning for Particle Physics**

*Modern machine learning techniques, including deep learning, is rapidly being applied, adapted, and developed for high energy physics.  The goal of this document is to provide a nearly comprehensive list of citations for those developing and applying these approaches to experimental, phenomenological, or theoretical analyses.  As a living document, it will be updated as often as possible to incorporate the latest developments.  A list of proper (unchanging) reviews can be found within.  Papers are grouped into a small set of topics to be as useful as possible.  Suggestions are most welcome.*

[![download](https://img.shields.io/badge/download-review-blue.svg)](https://iml-wg.github.io/HEPML-LivingReview/review/hepml-review.pdf)

The purpose of this note is to collect references for modern machine learning as applied to particle physics.  A minimal number of categories is chosen in order to be as useful as possible.  Note that papers may be referenced in more than one category.  The fact that a paper is listed in this document does not endorse or validate its content - that is for the community (and for peer-review) to decide.  Furthermore, the classification here is a best attempt and may have flaws - please let us know if (a) we have missed a paper you think should be included, (b) a paper has been misclassified, or (c) a citation for a paper is not correct or if the journal information is now available.  In order to be as useful as possible, this document will continue to evolve so please check back before you write your next paper.  If you find this review helpful, please consider citing it using \cite{hepmllivingreview} in HEPML.bib.


You can use the [editor on GitHub](https://github.com/yogeshverma1998/yogeshverma1998.github.io/edit/main/README.md) to maintain and preview the content for your website in Markdown files.

Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files.

### Markdown

Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3



- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [Basic writing and formatting syntax](https://docs.github.com/en/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/yogeshverma1998/yogeshverma1998.github.io/settings/pages). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://docs.github.com/categories/github-pages-basics/) or [contact support](https://support.github.com/contact) and we‚Äôll help you sort it out.
-->
